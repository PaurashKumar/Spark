{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d73ada4d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.006549,
     "end_time": "2023-10-12T19:57:23.668213",
     "exception": false,
     "start_time": "2023-10-12T19:57:23.661664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90175b2a",
   "metadata": {
    "papermill": {
     "duration": 0.005284,
     "end_time": "2023-10-12T19:57:23.680492",
     "exception": false,
     "start_time": "2023-10-12T19:57:23.675208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f8caf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:57:23.693821Z",
     "iopub.status.busy": "2023-10-12T19:57:23.693385Z",
     "iopub.status.idle": "2023-10-12T19:58:19.583200Z",
     "shell.execute_reply": "2023-10-12T19:58:19.582062Z"
    },
    "papermill": {
     "duration": 55.900373,
     "end_time": "2023-10-12T19:58:19.586391",
     "exception": false,
     "start_time": "2023-10-12T19:57:23.686018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Building wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425350 sha256=9d7c324208d0853300c7ec1781351ad949828fbd2bc071f789ac3d2415694b09\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: pyspark\r\n",
      "Successfully installed pyspark-3.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cf2639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:19.615278Z",
     "iopub.status.busy": "2023-10-12T19:58:19.614864Z",
     "iopub.status.idle": "2023-10-12T19:58:19.711488Z",
     "shell.execute_reply": "2023-10-12T19:58:19.710194Z"
    },
    "papermill": {
     "duration": 0.11396,
     "end_time": "2023-10-12T19:58:19.714247",
     "exception": false,
     "start_time": "2023-10-12T19:58:19.600287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c160d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:19.742119Z",
     "iopub.status.busy": "2023-10-12T19:58:19.741412Z",
     "iopub.status.idle": "2023-10-12T19:58:20.239838Z",
     "shell.execute_reply": "2023-10-12T19:58:20.238324Z"
    },
    "papermill": {
     "duration": 0.515342,
     "end_time": "2023-10-12T19:58:20.242318",
     "exception": false,
     "start_time": "2023-10-12T19:58:19.726976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paurash</td>\n",
       "      <td>25</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anushka</td>\n",
       "      <td>24</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prashi</td>\n",
       "      <td>23</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sankalp</td>\n",
       "      <td>24</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raj</td>\n",
       "      <td>27</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>angel</td>\n",
       "      <td>24</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name   age  city\n",
       "0  Paurash    25  BLG\n",
       
       "2   Prashi    23  BLG\n",
    
     
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"/kaggle/input/testing/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5f399e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:20.270970Z",
     "iopub.status.busy": "2023-10-12T19:58:20.269776Z",
     "iopub.status.idle": "2023-10-12T19:58:26.712323Z",
     "shell.execute_reply": "2023-10-12T19:58:26.711255Z"
    },
    "papermill": {
     "duration": 6.460351,
     "end_time": "2023-10-12T19:58:26.715413",
     "exception": false,
     "start_time": "2023-10-12T19:58:20.255062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/12 19:58:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Need to import to use date time\n",
    "from datetime import datetime, date\n",
    "\n",
    "# need to import to use pyspark\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# need to import for session creation\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# creating the session\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()\n",
    "\n",
    " \n",
    "\n",
    "# schema creation by passing list\n",
    "#df = spark.createDataFrame([\n",
    "#Row(a=1, b=4., c='GFG1', d=date(2000, 8, 1),\n",
    "#e=datetime(2000, 8, 1, 12, 0)),\n",
    "\n",
    "#Row(a=2, b=8., c='GFG2', d=date(2000, 6, 2),\n",
    "#e=datetime(2000, 6, 2, 12, 0)),\n",
    "\n",
    "#Row(a=4, b=5., c='GFG3', d=date(2000, 5, 3),\n",
    "#e=datetime(2000, 5, 3, 12, 0))\n",
    "#])\n",
    "\n",
    "# show table\n",
    "#df.show()\n",
    "\n",
    "# show schema\n",
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789d57ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:26.745326Z",
     "iopub.status.busy": "2023-10-12T19:58:26.744014Z",
     "iopub.status.idle": "2023-10-12T19:58:36.027713Z",
     "shell.execute_reply": "2023-10-12T19:58:36.026604Z"
    },
    "papermill": {
     "duration": 9.301828,
     "end_time": "2023-10-12T19:58:36.030452",
     "exception": false,
     "start_time": "2023-10-12T19:58:26.728624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+\n",
      "|    _c0| _c1| _c2|\n",
      "+-------+----+----+\n",
      "|  Name |age |city|\n",
      "|Paurash|  25| BLG|\n",
      "|Anushka|  24| BLG|\n",
      "| Prashi|  23| BLG|\n",
      "|sankalp|  24| BLG|\n",
      "|    raj|  27| BLG|\n",
      "|  angel|  24| BLG|\n",
      "+-------+----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Name ='Paurash', age ='25', city='BLG'),\n",
       " Row(Name ='Anushka', age ='24', city='BLG'),\n",
       " Row(Name ='Prashi', age ='23', city='BLG')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv(\"/kaggle/input/testing/Test.csv\")\n",
    "df_pyspark.show()\n",
    "df_pyspark=spark.read.option('header','true').csv(\"/kaggle/input/testing/Test.csv\")\n",
    "type(df_pyspark)\n",
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49797203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:36.061394Z",
     "iopub.status.busy": "2023-10-12T19:58:36.060609Z",
     "iopub.status.idle": "2023-10-12T19:58:47.267438Z",
     "shell.execute_reply": "2023-10-12T19:58:47.265958Z"
    },
    "papermill": {
     "duration": 11.226208,
     "end_time": "2023-10-12T19:58:47.270644",
     "exception": false,
     "start_time": "2023-10-12T19:58:36.044436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/conda/lib/python3.10/site-packages (3.5.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n"
     ]
    }
   ],
   "source": [
    "#date 10/13/2023\n",
    "#  -PySpark -Dataframe\n",
    "#  -Reading the datasets\n",
    "#  -Checking the datatypes of the column(Schema)\n",
    "#  -Selection Columns and Index\n",
    "#  _Checkin Describe option like to Pandas\n",
    "#  -Adding new column in data frame\n",
    "#  -Dropping new column in data frame\n",
    "\n",
    "!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2461a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:47.299733Z",
     "iopub.status.busy": "2023-10-12T19:58:47.298331Z",
     "iopub.status.idle": "2023-10-12T19:58:47.305377Z",
     "shell.execute_reply": "2023-10-12T19:58:47.304126Z"
    },
    "papermill": {
     "duration": 0.024258,
     "end_time": "2023-10-12T19:58:47.307871",
     "exception": false,
     "start_time": "2023-10-12T19:58:47.283613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9082901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:47.336092Z",
     "iopub.status.busy": "2023-10-12T19:58:47.335701Z",
     "iopub.status.idle": "2023-10-12T19:58:47.359348Z",
     "shell.execute_reply": "2023-10-12T19:58:47.357756Z"
    },
    "papermill": {
     "duration": 0.04157,
     "end_time": "2023-10-12T19:58:47.362285",
     "exception": false,
     "start_time": "2023-10-12T19:58:47.320715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 19:58:47 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c4ee04629d71:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7a6c04069c30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"Dataframe\").getOrCreate()\n",
    "\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d147e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:47.392497Z",
     "iopub.status.busy": "2023-10-12T19:58:47.392073Z",
     "iopub.status.idle": "2023-10-12T19:58:48.096949Z",
     "shell.execute_reply": "2023-10-12T19:58:48.095685Z"
    },
    "papermill": {
     "duration": 0.724231,
     "end_time": "2023-10-12T19:58:48.100644",
     "exception": false,
     "start_time": "2023-10-12T19:58:47.376413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the data set option -1\n",
    "df_pyspark=spark.read.option('header','true').csv('/kaggle/input/testing/Test.csv',inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be96695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:48.158189Z",
     "iopub.status.busy": "2023-10-12T19:58:48.157627Z",
     "iopub.status.idle": "2023-10-12T19:58:48.177834Z",
     "shell.execute_reply": "2023-10-12T19:58:48.176759Z"
    },
    "papermill": {
     "duration": 0.058783,
     "end_time": "2023-10-12T19:58:48.183098",
     "exception": false,
     "start_time": "2023-10-12T19:58:48.124315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name : string (nullable = true)\n",
      " |-- age : integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the schema\n",
    "\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3b24246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:48.234350Z",
     "iopub.status.busy": "2023-10-12T19:58:48.233411Z",
     "iopub.status.idle": "2023-10-12T19:58:48.721651Z",
     "shell.execute_reply": "2023-10-12T19:58:48.720265Z"
    },
    "papermill": {
     "duration": 0.517752,
     "end_time": "2023-10-12T19:58:48.725710",
     "exception": false,
     "start_time": "2023-10-12T19:58:48.207958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name : string (nullable = true)\n",
      " |-- age : integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the data set option - 2\n",
    "df_pyspark=spark.read.csv('/kaggle/input/testing/Test.csv',header=True,inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc54a46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:48.906428Z",
     "iopub.status.busy": "2023-10-12T19:58:48.905876Z",
     "iopub.status.idle": "2023-10-12T19:58:48.914185Z",
     "shell.execute_reply": "2023-10-12T19:58:48.913102Z"
    },
    "papermill": {
     "duration": 0.037831,
     "end_time": "2023-10-12T19:58:48.917574",
     "exception": false,
     "start_time": "2023-10-12T19:58:48.879743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee3f9ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:48.973412Z",
     "iopub.status.busy": "2023-10-12T19:58:48.972304Z",
     "iopub.status.idle": "2023-10-12T19:58:48.983608Z",
     "shell.execute_reply": "2023-10-12T19:58:48.982173Z"
    },
    "papermill": {
     "duration": 0.042383,
     "end_time": "2023-10-12T19:58:48.986089",
     "exception": false,
     "start_time": "2023-10-12T19:58:48.943706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name ', 'age ', 'city']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the column name\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc981731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:49.040962Z",
     "iopub.status.busy": "2023-10-12T19:58:49.039478Z",
     "iopub.status.idle": "2023-10-12T19:58:49.240476Z",
     "shell.execute_reply": "2023-10-12T19:58:49.239320Z"
    },
    "papermill": {
     "duration": 0.234883,
     "end_time": "2023-10-12T19:58:49.243792",
     "exception": false,
     "start_time": "2023-10-12T19:58:49.008909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name ='Paurash', age =25, city='BLG'),\n",
       " Row(Name ='Anushka', age =24, city='BLG')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find head and tail records\n",
    "df_pyspark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "526d2e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:49.300590Z",
     "iopub.status.busy": "2023-10-12T19:58:49.299237Z",
     "iopub.status.idle": "2023-10-12T19:58:49.435714Z",
     "shell.execute_reply": "2023-10-12T19:58:49.434571Z"
    },
    "papermill": {
     "duration": 0.167299,
     "end_time": "2023-10-12T19:58:49.439137",
     "exception": false,
     "start_time": "2023-10-12T19:58:49.271838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name ='raj', age =27, city='BLG'),\n",
       " Row(Name ='angel', age =24, city='BLG')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ba077e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:49.485817Z",
     "iopub.status.busy": "2023-10-12T19:58:49.485356Z",
     "iopub.status.idle": "2023-10-12T19:58:49.860706Z",
     "shell.execute_reply": "2023-10-12T19:58:49.859559Z"
    },
    "papermill": {
     "duration": 0.399418,
     "end_time": "2023-10-12T19:58:49.863812",
     "exception": false,
     "start_time": "2023-10-12T19:58:49.464394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  Name |\n",
      "+-------+\n",
      "|Paurash|\n",
      "|Anushka|\n",
      "| Prashi|\n",
      "|sankalp|\n",
      "|    raj|\n",
      "|  angel|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select the perticular column\n",
    "df_pyspark.select('Name ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ce72976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:49.917114Z",
     "iopub.status.busy": "2023-10-12T19:58:49.916434Z",
     "iopub.status.idle": "2023-10-12T19:58:50.175738Z",
     "shell.execute_reply": "2023-10-12T19:58:50.174387Z"
    },
    "papermill": {
     "duration": 0.290761,
     "end_time": "2023-10-12T19:58:50.179678",
     "exception": false,
     "start_time": "2023-10-12T19:58:49.888917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|  Name |age |\n",
      "+-------+----+\n",
      "|Paurash|  25|\n",
      "|Anushka|  24|\n",
      "| Prashi|  23|\n",
      "|sankalp|  24|\n",
      "|    raj|  27|\n",
      "|  angel|  24|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select the multiple columns\n",
    "df_pyspark.select('Name ','age ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2802c113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:50.220231Z",
     "iopub.status.busy": "2023-10-12T19:58:50.219776Z",
     "iopub.status.idle": "2023-10-12T19:58:50.226607Z",
     "shell.execute_reply": "2023-10-12T19:58:50.225444Z"
    },
    "papermill": {
     "duration": 0.026377,
     "end_time": "2023-10-12T19:58:50.229310",
     "exception": false,
     "start_time": "2023-10-12T19:58:50.202933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name ', 'string'), ('age ', 'int'), ('city', 'string')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the datatype\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dee9715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:50.261396Z",
     "iopub.status.busy": "2023-10-12T19:58:50.260493Z",
     "iopub.status.idle": "2023-10-12T19:58:52.184093Z",
     "shell.execute_reply": "2023-10-12T19:58:52.182699Z"
    },
    "papermill": {
     "duration": 1.944355,
     "end_time": "2023-10-12T19:58:52.188223",
     "exception": false,
     "start_time": "2023-10-12T19:58:50.243868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+----+\n",
      "|summary|  Name |             age |city|\n",
      "+-------+-------+-----------------+----+\n",
      "|  count|      6|                6|   6|\n",
      "|   mean|   NULL|             24.5|NULL|\n",
      "| stddev|   NULL|1.378404875209022|NULL|\n",
      "|    min|Anushka|               23| BLG|\n",
      "|    max|sankalp|               27| BLG|\n",
      "+-------+-------+-----------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# desrcibe funtions\n",
    "\n",
    "df_pyspark.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4719735f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:52.221987Z",
     "iopub.status.busy": "2023-10-12T19:58:52.221176Z",
     "iopub.status.idle": "2023-10-12T19:58:52.256067Z",
     "shell.execute_reply": "2023-10-12T19:58:52.254904Z"
    },
    "papermill": {
     "duration": 0.055387,
     "end_time": "2023-10-12T19:58:52.259891",
     "exception": false,
     "start_time": "2023-10-12T19:58:52.204504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Adding column in dataframes   withColumn()\n",
    "df_pyspark=df_pyspark.withColumn('age after 5 year',df_pyspark['age ']+5)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dcfa291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:52.300960Z",
     "iopub.status.busy": "2023-10-12T19:58:52.300375Z",
     "iopub.status.idle": "2023-10-12T19:58:52.484280Z",
     "shell.execute_reply": "2023-10-12T19:58:52.482916Z"
    },
    "papermill": {
     "duration": 0.205528,
     "end_time": "2023-10-12T19:58:52.487686",
     "exception": false,
     "start_time": "2023-10-12T19:58:52.282158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+----------------+\n",
      "|  Name |age |city|age after 5 year|\n",
      "+-------+----+----+----------------+\n",
      "|Paurash|  25| BLG|              30|\n",
      "|Anushka|  24| BLG|              29|\n",
      "| Prashi|  23| BLG|              28|\n",
      "|sankalp|  24| BLG|              29|\n",
      "|    raj|  27| BLG|              32|\n",
      "|  angel|  24| BLG|              29|\n",
      "+-------+----+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e68aa07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:52.543332Z",
     "iopub.status.busy": "2023-10-12T19:58:52.542926Z",
     "iopub.status.idle": "2023-10-12T19:58:52.734399Z",
     "shell.execute_reply": "2023-10-12T19:58:52.733114Z"
    },
    "papermill": {
     "duration": 0.223778,
     "end_time": "2023-10-12T19:58:52.738067",
     "exception": false,
     "start_time": "2023-10-12T19:58:52.514289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+\n",
      "|  Name |age |city|\n",
      "+-------+----+----+\n",
      "|Paurash|  25| BLG|\n",
      "|Anushka|  24| BLG|\n",
      "| Prashi|  23| BLG|\n",
      "|sankalp|  24| BLG|\n",
      "|    raj|  27| BLG|\n",
      "|  angel|  24| BLG|\n",
      "+-------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### drop the column \n",
    "\n",
    "df_pyspark=df_pyspark.drop('age after 5 year')\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92b612de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T19:58:52.783098Z",
     "iopub.status.busy": "2023-10-12T19:58:52.782643Z",
     "iopub.status.idle": "2023-10-12T19:58:52.801259Z",
     "shell.execute_reply": "2023-10-12T19:58:52.800107Z"
    },
    "papermill": {
     "duration": 0.038355,
     "end_time": "2023-10-12T19:58:52.803645",
     "exception": false,
     "start_time": "2023-10-12T19:58:52.765290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMPName', 'age ', 'city']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### re -Name the column\n",
    "\n",
    "df_pyspark=df_pyspark.withColumnRenamed('Name ','EMPName')\n",
    "\n",
    "type(df_pyspark)\n",
    "\n",
    "df_pyspark.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 95.329923,
   "end_time": "2023-10-12T19:58:55.440420",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-12T19:57:20.110497",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

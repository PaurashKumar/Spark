{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c698ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:44:27.337704Z",
     "iopub.status.busy": "2023-10-13T20:44:27.337092Z",
     "iopub.status.idle": "2023-10-13T20:45:16.777626Z",
     "shell.execute_reply": "2023-10-13T20:45:16.776296Z"
    },
    "papermill": {
     "duration": 49.457188,
     "end_time": "2023-10-13T20:45:16.780236",
     "exception": false,
     "start_time": "2023-10-13T20:44:27.323048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Building wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425350 sha256=1cd7f6340db390a2cde030a48a82bbe04f54a454a79772e9a6fab33d4cb603b1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: pyspark\r\n",
      "Successfully installed pyspark-3.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd210b83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:16.813451Z",
     "iopub.status.busy": "2023-10-13T20:45:16.813032Z",
     "iopub.status.idle": "2023-10-13T20:45:16.901421Z",
     "shell.execute_reply": "2023-10-13T20:45:16.900291Z"
    },
    "papermill": {
     "duration": 0.108437,
     "end_time": "2023-10-13T20:45:16.904247",
     "exception": false,
     "start_time": "2023-10-13T20:45:16.795810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fe90e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:16.937615Z",
     "iopub.status.busy": "2023-10-13T20:45:16.936925Z",
     "iopub.status.idle": "2023-10-13T20:45:17.394785Z",
     "shell.execute_reply": "2023-10-13T20:45:17.393393Z"
    },
    "papermill": {
     "duration": 0.477752,
     "end_time": "2023-10-13T20:45:17.397543",
     "exception": false,
     "start_time": "2023-10-13T20:45:16.919791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paurash</td>\n",
       "      <td>25</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prashi</td>\n",
       "      <td>23</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAA</td>\n",
       "      <td>25</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBBBBB</td>\n",
       "      <td>25</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCCC</td>\n",
       "      <td>25</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CCCCCC</td>\n",
       "      <td>25</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DDDDD</td>\n",
       "      <td>25</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EEEEEE</td>\n",
       "      <td>25</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name   age  city\n",
       "0  Paurash    25  BLG\n",
       "1   Prashi    23  BLG\n",
       "2    AAAAA    25  BLG\n",
       "3   BBBBBB    25  BLG\n",
       "4   CCCCCC    25  BLG\n",
       "5   CCCCCC    25  BLG\n",
       "6    DDDDD    25  BLG\n",
       "7   EEEEEE    25  BLG"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"/kaggle/input/testing1/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be8f6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:17.431661Z",
     "iopub.status.busy": "2023-10-13T20:45:17.431193Z",
     "iopub.status.idle": "2023-10-13T20:45:23.394167Z",
     "shell.execute_reply": "2023-10-13T20:45:23.393082Z"
    },
    "papermill": {
     "duration": 5.983313,
     "end_time": "2023-10-13T20:45:23.396959",
     "exception": false,
     "start_time": "2023-10-13T20:45:17.413646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/13 20:45:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Need to import to use date time\n",
    "from datetime import datetime, date\n",
    "\n",
    "# need to import to use pyspark\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# need to import for session creation\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# creating the session\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()\n",
    "\n",
    " \n",
    "\n",
    "# schema creation by passing list\n",
    "#df = spark.createDataFrame([\n",
    "#Row(a=1, b=4., c='GFG1', d=date(2000, 8, 1),\n",
    "#e=datetime(2000, 8, 1, 12, 0)),\n",
    "\n",
    "#Row(a=2, b=8., c='GFG2', d=date(2000, 6, 2),\n",
    "#e=datetime(2000, 6, 2, 12, 0)),\n",
    "\n",
    "#Row(a=4, b=5., c='GFG3', d=date(2000, 5, 3),\n",
    "#e=datetime(2000, 5, 3, 12, 0))\n",
    "#])\n",
    "\n",
    "# show table\n",
    "#df.show()\n",
    "\n",
    "# show schema\n",
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be94eecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:23.431598Z",
     "iopub.status.busy": "2023-10-13T20:45:23.430288Z",
     "iopub.status.idle": "2023-10-13T20:45:31.022505Z",
     "shell.execute_reply": "2023-10-13T20:45:31.021339Z"
    },
    "papermill": {
     "duration": 7.612393,
     "end_time": "2023-10-13T20:45:31.025661",
     "exception": false,
     "start_time": "2023-10-13T20:45:23.413268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+\n",
      "|    _c0| _c1| _c2|\n",
      "+-------+----+----+\n",
      "|  Name |age |city|\n",
      "|Paurash|  25| BLG|\n",
      "| Prashi|  23| BLG|\n",
      "|  AAAAA|  25| BLG|\n",
      "| BBBBBB|  25| BLG|\n",
      "| CCCCCC|  25| BLG|\n",
      "| CCCCCC|  25| BLG|\n",
      "|  DDDDD|  25| BLG|\n",
      "| EEEEEE|  25| BLG|\n",
      "+-------+----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Name ='Paurash', age ='25', city='BLG'),\n",
       " Row(Name ='Prashi', age ='23', city='BLG'),\n",
       " Row(Name ='AAAAA', age ='25', city='BLG')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv(\"/kaggle/input/testing1/Test.csv\")\n",
    "df_pyspark.show()\n",
    "df_pyspark=spark.read.option('header','true').csv(\"/kaggle/input/testing1/Test.csv\")\n",
    "type(df_pyspark)\n",
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006906e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:31.090271Z",
     "iopub.status.busy": "2023-10-13T20:45:31.089268Z",
     "iopub.status.idle": "2023-10-13T20:45:41.444574Z",
     "shell.execute_reply": "2023-10-13T20:45:41.443664Z"
    },
    "papermill": {
     "duration": 10.389332,
     "end_time": "2023-10-13T20:45:41.447052",
     "exception": false,
     "start_time": "2023-10-13T20:45:31.057720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/conda/lib/python3.10/site-packages (3.5.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n"
     ]
    }
   ],
   "source": [
    "#date 10/13/2023\n",
    "#  -PySpark -Dataframe\n",
    "#  -Reading the datasets\n",
    "#  -Checking the datatypes of the column(Schema)\n",
    "#  -Selection Columns and Index\n",
    "#  _Checkin Describe option like to Pandas\n",
    "#  -Adding new column in data frame\n",
    "#  -Dropping new column in data frame\n",
    "\n",
    "!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad84102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:41.481297Z",
     "iopub.status.busy": "2023-10-13T20:45:41.480923Z",
     "iopub.status.idle": "2023-10-13T20:45:41.484996Z",
     "shell.execute_reply": "2023-10-13T20:45:41.484336Z"
    },
    "papermill": {
     "duration": 0.023342,
     "end_time": "2023-10-13T20:45:41.486580",
     "exception": false,
     "start_time": "2023-10-13T20:45:41.463238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f800b294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:41.519308Z",
     "iopub.status.busy": "2023-10-13T20:45:41.518938Z",
     "iopub.status.idle": "2023-10-13T20:45:41.541297Z",
     "shell.execute_reply": "2023-10-13T20:45:41.539965Z"
    },
    "papermill": {
     "duration": 0.041198,
     "end_time": "2023-10-13T20:45:41.543391",
     "exception": false,
     "start_time": "2023-10-13T20:45:41.502193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/13 20:45:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b3c351e2b464:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x78317e5c9d50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"Dataframe\").getOrCreate()\n",
    "\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b82f25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:41.579318Z",
     "iopub.status.busy": "2023-10-13T20:45:41.578732Z",
     "iopub.status.idle": "2023-10-13T20:45:42.079548Z",
     "shell.execute_reply": "2023-10-13T20:45:42.078325Z"
    },
    "papermill": {
     "duration": 0.522689,
     "end_time": "2023-10-13T20:45:42.083186",
     "exception": false,
     "start_time": "2023-10-13T20:45:41.560497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the data set option -1\n",
    "df_pyspark=spark.read.option('header','true').csv('/kaggle/input/testing1/Test.csv',inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1fce5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:42.144940Z",
     "iopub.status.busy": "2023-10-13T20:45:42.144460Z",
     "iopub.status.idle": "2023-10-13T20:45:42.153695Z",
     "shell.execute_reply": "2023-10-13T20:45:42.152107Z"
    },
    "papermill": {
     "duration": 0.042718,
     "end_time": "2023-10-13T20:45:42.156267",
     "exception": false,
     "start_time": "2023-10-13T20:45:42.113549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name : string (nullable = true)\n",
      " |-- age : integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the schema\n",
    "\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8411e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:42.340140Z",
     "iopub.status.busy": "2023-10-13T20:45:42.339779Z",
     "iopub.status.idle": "2023-10-13T20:45:42.726306Z",
     "shell.execute_reply": "2023-10-13T20:45:42.725189Z"
    },
    "papermill": {
     "duration": 0.540264,
     "end_time": "2023-10-13T20:45:42.728504",
     "exception": false,
     "start_time": "2023-10-13T20:45:42.188240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name : string (nullable = true)\n",
      " |-- age : integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the data set option - 2\n",
    "df_pyspark=spark.read.csv('/kaggle/input/testing1/Test.csv',header=True,inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de99f460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:42.777187Z",
     "iopub.status.busy": "2023-10-13T20:45:42.776089Z",
     "iopub.status.idle": "2023-10-13T20:45:42.782873Z",
     "shell.execute_reply": "2023-10-13T20:45:42.781983Z"
    },
    "papermill": {
     "duration": 0.03871,
     "end_time": "2023-10-13T20:45:42.784870",
     "exception": false,
     "start_time": "2023-10-13T20:45:42.746160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ea8c24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:42.819787Z",
     "iopub.status.busy": "2023-10-13T20:45:42.819051Z",
     "iopub.status.idle": "2023-10-13T20:45:42.828520Z",
     "shell.execute_reply": "2023-10-13T20:45:42.827752Z"
    },
    "papermill": {
     "duration": 0.029457,
     "end_time": "2023-10-13T20:45:42.830838",
     "exception": false,
     "start_time": "2023-10-13T20:45:42.801381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name ', 'age ', 'city']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the column name\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d242141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:42.865782Z",
     "iopub.status.busy": "2023-10-13T20:45:42.865450Z",
     "iopub.status.idle": "2023-10-13T20:45:43.054871Z",
     "shell.execute_reply": "2023-10-13T20:45:43.053688Z"
    },
    "papermill": {
     "duration": 0.209958,
     "end_time": "2023-10-13T20:45:43.057871",
     "exception": false,
     "start_time": "2023-10-13T20:45:42.847913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name ='Paurash', age =25, city='BLG'),\n",
       " Row(Name ='Prashi', age =23, city='BLG')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find head and tail records\n",
    "df_pyspark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0fadaeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:43.125850Z",
     "iopub.status.busy": "2023-10-13T20:45:43.124908Z",
     "iopub.status.idle": "2023-10-13T20:45:43.261830Z",
     "shell.execute_reply": "2023-10-13T20:45:43.260832Z"
    },
    "papermill": {
     "duration": 0.174664,
     "end_time": "2023-10-13T20:45:43.264769",
     "exception": false,
     "start_time": "2023-10-13T20:45:43.090105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name ='DDDDD', age =25, city='BLG'),\n",
       " Row(Name ='EEEEEE', age =25, city='BLG')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7434055f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:43.331047Z",
     "iopub.status.busy": "2023-10-13T20:45:43.330151Z",
     "iopub.status.idle": "2023-10-13T20:45:43.653640Z",
     "shell.execute_reply": "2023-10-13T20:45:43.651735Z"
    },
    "papermill": {
     "duration": 0.360373,
     "end_time": "2023-10-13T20:45:43.656850",
     "exception": false,
     "start_time": "2023-10-13T20:45:43.296477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  Name |\n",
      "+-------+\n",
      "|Paurash|\n",
      "| Prashi|\n",
      "|  AAAAA|\n",
      "| BBBBBB|\n",
      "| CCCCCC|\n",
      "| CCCCCC|\n",
      "|  DDDDD|\n",
      "| EEEEEE|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select the perticular column\n",
    "df_pyspark.select('Name ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13dc0b85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:43.726755Z",
     "iopub.status.busy": "2023-10-13T20:45:43.726284Z",
     "iopub.status.idle": "2023-10-13T20:45:43.946373Z",
     "shell.execute_reply": "2023-10-13T20:45:43.945273Z"
    },
    "papermill": {
     "duration": 0.256631,
     "end_time": "2023-10-13T20:45:43.949489",
     "exception": false,
     "start_time": "2023-10-13T20:45:43.692858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|  Name |age |\n",
      "+-------+----+\n",
      "|Paurash|  25|\n",
      "| Prashi|  23|\n",
      "|  AAAAA|  25|\n",
      "| BBBBBB|  25|\n",
      "| CCCCCC|  25|\n",
      "| CCCCCC|  25|\n",
      "|  DDDDD|  25|\n",
      "| EEEEEE|  25|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select the multiple columns\n",
    "df_pyspark.select('Name ','age ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "416891eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:44.012882Z",
     "iopub.status.busy": "2023-10-13T20:45:44.012424Z",
     "iopub.status.idle": "2023-10-13T20:45:44.019898Z",
     "shell.execute_reply": "2023-10-13T20:45:44.018945Z"
    },
    "papermill": {
     "duration": 0.042188,
     "end_time": "2023-10-13T20:45:44.022702",
     "exception": false,
     "start_time": "2023-10-13T20:45:43.980514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name ', 'string'), ('age ', 'int'), ('city', 'string')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the datatype\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a552df78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:44.077133Z",
     "iopub.status.busy": "2023-10-13T20:45:44.076817Z",
     "iopub.status.idle": "2023-10-13T20:45:45.593092Z",
     "shell.execute_reply": "2023-10-13T20:45:45.592018Z"
    },
    "papermill": {
     "duration": 1.53982,
     "end_time": "2023-10-13T20:45:45.595977",
     "exception": false,
     "start_time": "2023-10-13T20:45:44.056157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+----+\n",
      "|summary| Name |              age |city|\n",
      "+-------+------+------------------+----+\n",
      "|  count|     8|                 8|   8|\n",
      "|   mean|  NULL|             24.75|NULL|\n",
      "| stddev|  NULL|0.7071067811865475|NULL|\n",
      "|    min| AAAAA|                23| BLG|\n",
      "|    max|Prashi|                25| BLG|\n",
      "+-------+------+------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# desrcibe funtions\n",
    "\n",
    "df_pyspark.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05e9a3c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:45.632558Z",
     "iopub.status.busy": "2023-10-13T20:45:45.632162Z",
     "iopub.status.idle": "2023-10-13T20:45:45.663562Z",
     "shell.execute_reply": "2023-10-13T20:45:45.662586Z"
    },
    "papermill": {
     "duration": 0.052689,
     "end_time": "2023-10-13T20:45:45.666344",
     "exception": false,
     "start_time": "2023-10-13T20:45:45.613655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Adding column in dataframes   withColumn()\n",
    "df_pyspark=df_pyspark.withColumn('age after 5 year',df_pyspark['age ']+5)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a730ae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:45.703817Z",
     "iopub.status.busy": "2023-10-13T20:45:45.703434Z",
     "iopub.status.idle": "2023-10-13T20:45:45.848768Z",
     "shell.execute_reply": "2023-10-13T20:45:45.847562Z"
    },
    "papermill": {
     "duration": 0.167119,
     "end_time": "2023-10-13T20:45:45.851425",
     "exception": false,
     "start_time": "2023-10-13T20:45:45.684306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+----------------+\n",
      "|  Name |age |city|age after 5 year|\n",
      "+-------+----+----+----------------+\n",
      "|Paurash|  25| BLG|              30|\n",
      "| Prashi|  23| BLG|              28|\n",
      "|  AAAAA|  25| BLG|              30|\n",
      "| BBBBBB|  25| BLG|              30|\n",
      "| CCCCCC|  25| BLG|              30|\n",
      "| CCCCCC|  25| BLG|              30|\n",
      "|  DDDDD|  25| BLG|              30|\n",
      "| EEEEEE|  25| BLG|              30|\n",
      "+-------+----+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "265727db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:45.911466Z",
     "iopub.status.busy": "2023-10-13T20:45:45.910988Z",
     "iopub.status.idle": "2023-10-13T20:45:46.096761Z",
     "shell.execute_reply": "2023-10-13T20:45:46.095648Z"
    },
    "papermill": {
     "duration": 0.219693,
     "end_time": "2023-10-13T20:45:46.100050",
     "exception": false,
     "start_time": "2023-10-13T20:45:45.880357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+\n",
      "|  Name |age |city|\n",
      "+-------+----+----+\n",
      "|Paurash|  25| BLG|\n",
      "| Prashi|  23| BLG|\n",
      "|  AAAAA|  25| BLG|\n",
      "| BBBBBB|  25| BLG|\n",
      "| CCCCCC|  25| BLG|\n",
      "| CCCCCC|  25| BLG|\n",
      "|  DDDDD|  25| BLG|\n",
      "| EEEEEE|  25| BLG|\n",
      "+-------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### drop the column \n",
    "\n",
    "df_pyspark=df_pyspark.drop('age after 5 year')\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5110ee8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:46.156133Z",
     "iopub.status.busy": "2023-10-13T20:45:46.155815Z",
     "iopub.status.idle": "2023-10-13T20:45:46.171860Z",
     "shell.execute_reply": "2023-10-13T20:45:46.170724Z"
    },
    "papermill": {
     "duration": 0.040679,
     "end_time": "2023-10-13T20:45:46.175227",
     "exception": false,
     "start_time": "2023-10-13T20:45:46.134548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMPName', 'age ', 'city']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### re -Name the column\n",
    "\n",
    "df_pyspark=df_pyspark.withColumnRenamed('Name ','EMPName')\n",
    "\n",
    "type(df_pyspark)\n",
    "\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e061e",
   "metadata": {
    "papermill": {
     "duration": 0.01705,
     "end_time": "2023-10-13T20:45:46.214634",
     "exception": false,
     "start_time": "2023-10-13T20:45:46.197584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pyspark Handling Missing Values\n",
    "# dropping columns\n",
    "# dropping rows\n",
    "# Various Parameter in Dropping functionalities\n",
    "# Handling Missing values by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c82325d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:46.260749Z",
     "iopub.status.busy": "2023-10-13T20:45:46.259706Z",
     "iopub.status.idle": "2023-10-13T20:45:56.593090Z",
     "shell.execute_reply": "2023-10-13T20:45:56.591879Z"
    },
    "papermill": {
     "duration": 10.358446,
     "end_time": "2023-10-13T20:45:56.595240",
     "exception": false,
     "start_time": "2023-10-13T20:45:46.236794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/conda/lib/python3.10/site-packages (3.5.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/13 20:45:56 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspark\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Practise\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e6f1691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:56.633573Z",
     "iopub.status.busy": "2023-10-13T20:45:56.633109Z",
     "iopub.status.idle": "2023-10-13T20:45:57.217361Z",
     "shell.execute_reply": "2023-10-13T20:45:57.216139Z"
    },
    "papermill": {
     "duration": 0.6083,
     "end_time": "2023-10-13T20:45:57.220828",
     "exception": false,
     "start_time": "2023-10-13T20:45:56.612528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('/kaggle/input/testing3/Test2.csv', header=True,inferSchema=True)\n",
    "df_pyspark1=spark.read.csv('/kaggle/input/testing4/Test3.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83800e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:57.288157Z",
     "iopub.status.busy": "2023-10-13T20:45:57.287569Z",
     "iopub.status.idle": "2023-10-13T20:45:57.456968Z",
     "shell.execute_reply": "2023-10-13T20:45:57.455805Z"
    },
    "papermill": {
     "duration": 0.206752,
     "end_time": "2023-10-13T20:45:57.460257",
     "exception": false,
     "start_time": "2023-10-13T20:45:57.253505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+\n",
      "|   Name| age|city|Salary|\n",
      "+-------+----+----+------+\n",
      "|Paurash|  25| BLG|100000|\n",
      "| Prashi|  23| BLG| 80000|\n",
      "|  AAAAA|  25| HYR| 70000|\n",
      "| BBBBBB|NULL| GUR| 65000|\n",
      "| CCCCCC|NULL| NOI| 76000|\n",
      "| CCCCCC|  25| RAI|  NULL|\n",
      "|  DDDDD|  25|NULL|125000|\n",
      "| EEEEEE|  25|NULL|250000|\n",
      "+-------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bebd0f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:57.524715Z",
     "iopub.status.busy": "2023-10-13T20:45:57.524336Z",
     "iopub.status.idle": "2023-10-13T20:45:57.682079Z",
     "shell.execute_reply": "2023-10-13T20:45:57.680894Z"
    },
    "papermill": {
     "duration": 0.192959,
     "end_time": "2023-10-13T20:45:57.685124",
     "exception": false,
     "start_time": "2023-10-13T20:45:57.492165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|   Name| age|Salary|\n",
      "+-------+----+------+\n",
      "|Paurash|  25|100000|\n",
      "| Prashi|  23| 80000|\n",
      "|  AAAAA|  25| 70000|\n",
      "| BBBBBB|NULL| 65000|\n",
      "| CCCCCC|NULL| 76000|\n",
      "| CCCCCC|  25|  NULL|\n",
      "|  DDDDD|  25|125000|\n",
      "| EEEEEE|  25|250000|\n",
      "+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the column\n",
    "df_pyspark1.drop('city').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64ee04db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:57.723764Z",
     "iopub.status.busy": "2023-10-13T20:45:57.723293Z",
     "iopub.status.idle": "2023-10-13T20:45:57.949340Z",
     "shell.execute_reply": "2023-10-13T20:45:57.947886Z"
    },
    "papermill": {
     "duration": 0.249778,
     "end_time": "2023-10-13T20:45:57.953519",
     "exception": false,
     "start_time": "2023-10-13T20:45:57.703741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+\n",
      "|   Name| age|city|Salary|\n",
      "+-------+----+----+------+\n",
      "|Paurash|  25| BLG|100000|\n",
      "| Prashi|  23| BLG| 80000|\n",
      "|  AAAAA|  25| HYR| 70000|\n",
      "| BBBBBB|NULL| GUR| 65000|\n",
      "| CCCCCC|NULL| NOI| 76000|\n",
      "| CCCCCC|  25| RAI|  NULL|\n",
      "|  DDDDD|  25|NULL|125000|\n",
      "| EEEEEE|  25|NULL|250000|\n",
      "+-------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e417b2e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:58.031634Z",
     "iopub.status.busy": "2023-10-13T20:45:58.019042Z",
     "iopub.status.idle": "2023-10-13T20:45:58.283074Z",
     "shell.execute_reply": "2023-10-13T20:45:58.282000Z"
    },
    "papermill": {
     "duration": 0.302092,
     "end_time": "2023-10-13T20:45:58.286512",
     "exception": false,
     "start_time": "2023-10-13T20:45:57.984420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+------+\n",
      "|   Name|age|city|Salary|\n",
      "+-------+---+----+------+\n",
      "|Paurash| 25| BLG|100000|\n",
      "| Prashi| 23| BLG| 80000|\n",
      "|  AAAAA| 25| HYR| 70000|\n",
      "+-------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove all Rows in the datasets which have NULL values\n",
    "df_pyspark1.na.drop().show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e02b5",
   "metadata": {
    "papermill": {
     "duration": 0.031236,
     "end_time": "2023-10-13T20:45:58.352380",
     "exception": false,
     "start_time": "2023-10-13T20:45:58.321144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# drop has 3 parametes (how='any/all', thresh=any number,subset=['column name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd1d285d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:58.394645Z",
     "iopub.status.busy": "2023-10-13T20:45:58.394317Z",
     "iopub.status.idle": "2023-10-13T20:45:58.519306Z",
     "shell.execute_reply": "2023-10-13T20:45:58.518164Z"
    },
    "papermill": {
     "duration": 0.147482,
     "end_time": "2023-10-13T20:45:58.522614",
     "exception": false,
     "start_time": "2023-10-13T20:45:58.375132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+------+\n",
      "|   Name|age|city|Salary|\n",
      "+-------+---+----+------+\n",
      "|Paurash| 25| BLG|100000|\n",
      "| Prashi| 23| BLG| 80000|\n",
      "|  AAAAA| 25| HYR| 70000|\n",
      "+-------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove all Row rows that have at least one NULL values  set (any / all)\n",
    "df_pyspark1.na.drop(how='any').show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20117071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:58.584293Z",
     "iopub.status.busy": "2023-10-13T20:45:58.583910Z",
     "iopub.status.idle": "2023-10-13T20:45:58.751311Z",
     "shell.execute_reply": "2023-10-13T20:45:58.750282Z"
    },
    "papermill": {
     "duration": 0.198913,
     "end_time": "2023-10-13T20:45:58.754348",
     "exception": false,
     "start_time": "2023-10-13T20:45:58.555435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+\n",
      "|   Name| age|city|Salary|\n",
      "+-------+----+----+------+\n",
      "|Paurash|  25| BLG|100000|\n",
      "| Prashi|  23| BLG| 80000|\n",
      "|  AAAAA|  25| HYR| 70000|\n",
      "| BBBBBB|NULL| GUR| 65000|\n",
      "| CCCCCC|NULL| NOI| 76000|\n",
      "| CCCCCC|  25| RAI|  NULL|\n",
      "|  DDDDD|  25|NULL|125000|\n",
      "| EEEEEE|  25|NULL|250000|\n",
      "+-------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "039d88b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:58.821854Z",
     "iopub.status.busy": "2023-10-13T20:45:58.821385Z",
     "iopub.status.idle": "2023-10-13T20:45:58.965562Z",
     "shell.execute_reply": "2023-10-13T20:45:58.964302Z"
    },
    "papermill": {
     "duration": 0.180203,
     "end_time": "2023-10-13T20:45:58.967638",
     "exception": false,
     "start_time": "2023-10-13T20:45:58.787435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+------+\n",
      "|   Name|age|city|Salary|\n",
      "+-------+---+----+------+\n",
      "|Paurash| 25| BLG|100000|\n",
      "| Prashi| 23| BLG| 80000|\n",
      "|  AAAAA| 25| HYR| 70000|\n",
      "+-------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### threshold  we can set threshold 1,2,3,4,,,,,,---> any number based on colums numbers\n",
    "df_pyspark1.na.drop(how='any',thresh=4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0784442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:59.004964Z",
     "iopub.status.busy": "2023-10-13T20:45:59.004593Z",
     "iopub.status.idle": "2023-10-13T20:45:59.132798Z",
     "shell.execute_reply": "2023-10-13T20:45:59.131558Z"
    },
    "papermill": {
     "duration": 0.150083,
     "end_time": "2023-10-13T20:45:59.135608",
     "exception": false,
     "start_time": "2023-10-13T20:45:58.985525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+\n",
      "|   Name| age|city|Salary|\n",
      "+-------+----+----+------+\n",
      "|Paurash|  25| BLG|100000|\n",
      "| Prashi|  23| BLG| 80000|\n",
      "|  AAAAA|  25| HYR| 70000|\n",
      "| BBBBBB|NULL| GUR| 65000|\n",
      "| CCCCCC|NULL| NOI| 76000|\n",
      "| CCCCCC|  25| RAI|  NULL|\n",
      "|  DDDDD|  25|NULL|125000|\n",
      "| EEEEEE|  25|NULL|250000|\n",
      "+-------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### threshold  we can set threshold 1,2,3,4,,,,,,---> any number based on colums numbers\n",
    "df_pyspark1.na.drop(how='any',thresh=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6df7616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:59.179685Z",
     "iopub.status.busy": "2023-10-13T20:45:59.179108Z",
     "iopub.status.idle": "2023-10-13T20:45:59.338574Z",
     "shell.execute_reply": "2023-10-13T20:45:59.337435Z"
    },
    "papermill": {
     "duration": 0.18171,
     "end_time": "2023-10-13T20:45:59.341069",
     "exception": false,
     "start_time": "2023-10-13T20:45:59.159359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+\n",
      "|   Name| age|city|Salary|\n",
      "+-------+----+----+------+\n",
      "|Paurash|  25| BLG|100000|\n",
      "| Prashi|  23| BLG| 80000|\n",
      "|  AAAAA|  25| HYR| 70000|\n",
      "| BBBBBB|NULL| GUR| 65000|\n",
      "| CCCCCC|NULL| NOI| 76000|\n",
      "| CCCCCC|  25| RAI|  NULL|\n",
      "|  DDDDD|  25|NULL|125000|\n",
      "| EEEEEE|  25|NULL|250000|\n",
      "+-------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### threshold  we can set threshold 1,2,3,4,,,,,,---> any number based on colums numbers\n",
    "df_pyspark1.na.drop(how='any',thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2a62f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:59.378911Z",
     "iopub.status.busy": "2023-10-13T20:45:59.378584Z",
     "iopub.status.idle": "2023-10-13T20:45:59.498950Z",
     "shell.execute_reply": "2023-10-13T20:45:59.497659Z"
    },
    "papermill": {
     "duration": 0.142471,
     "end_time": "2023-10-13T20:45:59.501764",
     "exception": false,
     "start_time": "2023-10-13T20:45:59.359293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+\n",
      "|   Name| age|city|Salary|\n",
      "+-------+----+----+------+\n",
      "|Paurash|  25| BLG|100000|\n",
      "| Prashi|  23| BLG| 80000|\n",
      "|  AAAAA|  25| HYR| 70000|\n",
      "| BBBBBB|NULL| GUR| 65000|\n",
      "| CCCCCC|NULL| NOI| 76000|\n",
      "| CCCCCC|  25| RAI|  NULL|\n",
      "|  DDDDD|  25|NULL|125000|\n",
      "| EEEEEE|  25|NULL|250000|\n",
      "+-------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### threshold  we can set threshold 1,2,3,4,,,,,,---> any number based on colums numbers\n",
    "df_pyspark1.na.drop(how='any',thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9fcdbea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:59.567623Z",
     "iopub.status.busy": "2023-10-13T20:45:59.567033Z",
     "iopub.status.idle": "2023-10-13T20:45:59.690490Z",
     "shell.execute_reply": "2023-10-13T20:45:59.689311Z"
    },
    "papermill": {
     "duration": 0.1601,
     "end_time": "2023-10-13T20:45:59.692957",
     "exception": false,
     "start_time": "2023-10-13T20:45:59.532857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+------+\n",
      "|   Name|age|city|Salary|\n",
      "+-------+---+----+------+\n",
      "|Paurash| 25| BLG|100000|\n",
      "| Prashi| 23| BLG| 80000|\n",
      "|  AAAAA| 25| HYR| 70000|\n",
      "+-------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### threshold  we can set threshold 1,2,3,4,,,,,,---> any number based on colums numbers\n",
    "df_pyspark1.na.drop(how='any',thresh=4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f4f6775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:59.733236Z",
     "iopub.status.busy": "2023-10-13T20:45:59.732632Z",
     "iopub.status.idle": "2023-10-13T20:45:59.878461Z",
     "shell.execute_reply": "2023-10-13T20:45:59.877301Z"
    },
    "papermill": {
     "duration": 0.16886,
     "end_time": "2023-10-13T20:45:59.881676",
     "exception": false,
     "start_time": "2023-10-13T20:45:59.712816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+------+\n",
      "|   Name|age|city|Salary|\n",
      "+-------+---+----+------+\n",
      "|Paurash| 25| BLG|100000|\n",
      "| Prashi| 23| BLG| 80000|\n",
      "|  AAAAA| 25| HYR| 70000|\n",
      "| CCCCCC| 25| RAI|  NULL|\n",
      "|  DDDDD| 25|NULL|125000|\n",
      "| EEEEEE| 25|NULL|250000|\n",
      "+-------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## subset  -> we can provide column numes in the subset the it will filter based on perticular column\n",
    "# remove the row that contains NULL values\n",
    "df_pyspark1.na.drop(how='any',subset=['age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a45b296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:45:59.951787Z",
     "iopub.status.busy": "2023-10-13T20:45:59.951218Z",
     "iopub.status.idle": "2023-10-13T20:46:00.106176Z",
     "shell.execute_reply": "2023-10-13T20:46:00.104767Z"
    },
    "papermill": {
     "duration": 0.194328,
     "end_time": "2023-10-13T20:46:00.110070",
     "exception": false,
     "start_time": "2023-10-13T20:45:59.915742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+------+\n",
      "|   Name|age|city|Salary|\n",
      "+-------+---+----+------+\n",
      "|Paurash| 25| BLG|100000|\n",
      "| Prashi| 23| BLG| 80000|\n",
      "|  AAAAA| 25| HYR| 70000|\n",
      "+-------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.drop(how='any',subset=['age','city','salary']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06100e42",
   "metadata": {
    "papermill": {
     "duration": 0.017998,
     "end_time": "2023-10-13T20:46:00.155114",
     "exception": false,
     "start_time": "2023-10-13T20:46:00.137116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Filling the Missing Values in the NULL Fields\n",
    "# fill has 2 parameters -> value and subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7231147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:46:00.192646Z",
     "iopub.status.busy": "2023-10-13T20:46:00.192247Z",
     "iopub.status.idle": "2023-10-13T20:46:00.333018Z",
     "shell.execute_reply": "2023-10-13T20:46:00.331816Z"
    },
    "papermill": {
     "duration": 0.162371,
     "end_time": "2023-10-13T20:46:00.335389",
     "exception": false,
     "start_time": "2023-10-13T20:46:00.173018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------------+------+\n",
      "|   Name| age|         city|Salary|\n",
      "+-------+----+-------------+------+\n",
      "|Paurash|  25|          BLG|100000|\n",
      "| Prashi|  23|          BLG| 80000|\n",
      "|  AAAAA|  25|          HYR| 70000|\n",
      "| BBBBBB|NULL|          GUR| 65000|\n",
      "| CCCCCC|NULL|          NOI| 76000|\n",
      "| CCCCCC|  25|          RAI|  NULL|\n",
      "|  DDDDD|  25|Missing value|125000|\n",
      "| EEEEEE|  25|Missing value|250000|\n",
      "+-------+----+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.fill('Missing value').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f70b7b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:46:00.378335Z",
     "iopub.status.busy": "2023-10-13T20:46:00.377122Z",
     "iopub.status.idle": "2023-10-13T20:46:00.547417Z",
     "shell.execute_reply": "2023-10-13T20:46:00.546344Z"
    },
    "papermill": {
     "duration": 0.195892,
     "end_time": "2023-10-13T20:46:00.550473",
     "exception": false,
     "start_time": "2023-10-13T20:46:00.354581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------+------+\n",
      "|   Name| age|          city|Salary|\n",
      "+-------+----+--------------+------+\n",
      "|Paurash|  25|           BLG|100000|\n",
      "| Prashi|  23|           BLG| 80000|\n",
      "|  AAAAA|  25|           HYR| 70000|\n",
      "| BBBBBB|NULL|           GUR| 65000|\n",
      "| CCCCCC|NULL|           NOI| 76000|\n",
      "| CCCCCC|  25|           RAI|  NULL|\n",
      "|  DDDDD|  25|Missing Values|125000|\n",
      "| EEEEEE|  25|Missing Values|250000|\n",
      "+-------+----+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.fill('Missing Values',subset=['age','Salary','city']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc82e8",
   "metadata": {
    "papermill": {
     "duration": 0.035778,
     "end_time": "2023-10-13T20:46:00.628614",
     "exception": false,
     "start_time": "2023-10-13T20:46:00.592836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# because age and Salary are Integer fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5571e084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:46:00.695536Z",
     "iopub.status.busy": "2023-10-13T20:46:00.694819Z",
     "iopub.status.idle": "2023-10-13T20:46:00.857069Z",
     "shell.execute_reply": "2023-10-13T20:46:00.855949Z"
    },
    "papermill": {
     "duration": 0.198291,
     "end_time": "2023-10-13T20:46:00.860400",
     "exception": false,
     "start_time": "2023-10-13T20:46:00.662109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+------+\n",
      "|   Name|age|city|Salary|\n",
      "+-------+---+----+------+\n",
      "|Paurash| 25| BLG|100000|\n",
      "| Prashi| 23| BLG| 80000|\n",
      "|  AAAAA| 25| HYR| 70000|\n",
      "| BBBBBB| 33| GUR| 65000|\n",
      "| CCCCCC| 33| NOI| 76000|\n",
      "| CCCCCC| 25| RAI|  NULL|\n",
      "|  DDDDD| 25|NULL|125000|\n",
      "| EEEEEE| 25|NULL|250000|\n",
      "+-------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.fill(33,subset=['age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33b671d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:46:00.917432Z",
     "iopub.status.busy": "2023-10-13T20:46:00.917045Z",
     "iopub.status.idle": "2023-10-13T20:46:01.062117Z",
     "shell.execute_reply": "2023-10-13T20:46:01.061075Z"
    },
    "papermill": {
     "duration": 0.170125,
     "end_time": "2023-10-13T20:46:01.064682",
     "exception": false,
     "start_time": "2023-10-13T20:46:00.894557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----+------+\n",
      "|   Name|  age|city|Salary|\n",
      "+-------+-----+----+------+\n",
      "|Paurash|   25| BLG|100000|\n",
      "| Prashi|   23| BLG| 80000|\n",
      "|  AAAAA|   25| HYR| 70000|\n",
      "| BBBBBB|50000| GUR| 65000|\n",
      "| CCCCCC|50000| NOI| 76000|\n",
      "| CCCCCC|   25| RAI|  NULL|\n",
      "|  DDDDD|   25|NULL|125000|\n",
      "| EEEEEE|   25|NULL|250000|\n",
      "+-------+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.fill(50000,subset=['age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4e07d",
   "metadata": {
    "papermill": {
     "duration": 0.018217,
     "end_time": "2023-10-13T20:46:01.102320",
     "exception": false,
     "start_time": "2023-10-13T20:46:01.084103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Handling Missing values by mean /mode /Medium throught imputer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fb474c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:46:01.143144Z",
     "iopub.status.busy": "2023-10-13T20:46:01.142747Z",
     "iopub.status.idle": "2023-10-13T20:46:01.618262Z",
     "shell.execute_reply": "2023-10-13T20:46:01.617070Z"
    },
    "papermill": {
     "duration": 0.500246,
     "end_time": "2023-10-13T20:46:01.620797",
     "exception": false,
     "start_time": "2023-10-13T20:46:01.120551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer=Imputer(\n",
    "    inputCols=['age','Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age','Salary']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53568476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:46:01.659982Z",
     "iopub.status.busy": "2023-10-13T20:46:01.659255Z",
     "iopub.status.idle": "2023-10-13T20:46:02.451436Z",
     "shell.execute_reply": "2023-10-13T20:46:02.450551Z"
    },
    "papermill": {
     "duration": 0.814714,
     "end_time": "2023-10-13T20:46:02.454487",
     "exception": false,
     "start_time": "2023-10-13T20:46:01.639773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+-----------+--------------+\n",
      "|   Name| age|city|Salary|age_imputed|Salary_imputed|\n",
      "+-------+----+----+------+-----------+--------------+\n",
      "|Paurash|  25| BLG|100000|         25|        100000|\n",
      "| Prashi|  23| BLG| 80000|         23|         80000|\n",
      "|  AAAAA|  25| HYR| 70000|         25|         70000|\n",
      "| BBBBBB|NULL| GUR| 65000|         24|         65000|\n",
      "| CCCCCC|NULL| NOI| 76000|         24|         76000|\n",
      "| CCCCCC|  25| RAI|  NULL|         25|        109428|\n",
      "|  DDDDD|  25|NULL|125000|         25|        125000|\n",
      "| EEEEEE|  25|NULL|250000|         25|        250000|\n",
      "+-------+----+----+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark1).transform(df_pyspark1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83715e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T20:46:02.522943Z",
     "iopub.status.busy": "2023-10-13T20:46:02.522413Z",
     "iopub.status.idle": "2023-10-13T20:46:02.530152Z",
     "shell.execute_reply": "2023-10-13T20:46:02.529172Z"
    },
    "papermill": {
     "duration": 0.045896,
     "end_time": "2023-10-13T20:46:02.533254",
     "exception": false,
     "start_time": "2023-10-13T20:46:02.487358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 101.180856,
   "end_time": "2023-10-13T20:46:05.179489",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-13T20:44:23.998633",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
